{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGob6jyYNbR3wMKwLpINjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriku2412/Personal-projects/blob/main/TranscribeAudio_240110.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that Ai can generate or replicate voice. We need a voice to text and text to voice that would improve security. It’s as if from a James bond movie where he hides his identity with an encoder decoder recording software built in phone to mask the voice.\n",
        "But can it be done in real time? I need to give it a try at least so taking baby steps here is my first try at encoding and decoding voice. We would then look if the possible to have a CI/CD pipeline or have alternate options for it.\n",
        "\n",
        "Just like James Bond said - \"I Always Enjoyed Studying A New Tongue.\""
      ],
      "metadata": {
        "id": "F2dIrPiWEXqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9-nKQeSBlTd",
        "outputId": "924e98fc-1c1b-4b69-ecca-cd4541f8425e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-xsdqcawv\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-xsdqcawv\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "29 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "# The command to run whisper and capture its output\n",
        "command = 'whisper \"Tutorial.mp3\" --model medium.en'\n",
        "\n",
        "try:\n",
        "    # Run the command and capture its output\n",
        "    output = subprocess.check_output(command, shell=True, text=True)\n",
        "\n",
        "    # Save the output as a string\n",
        "    result_text = str(output)\n",
        "\n",
        "    # You can print the result if needed\n",
        "    print(result_text)\n",
        "\n",
        "    # Optionally, save the result to a file\n",
        "    with open(\"whisper_output.txt\", \"w\") as file:\n",
        "        file.write(result_text)\n",
        "\n",
        "except subprocess.CalledProcessError as e:\n",
        "    # Handle any errors that might occur\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLJlWa3Gmx8",
        "outputId": "f22c00a1-7ccc-4776-ef4d-0872c17089b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:04.420]  Hello everyone and welcome back to my channel Jennifer Marie where I teach you\n",
            "[00:04.420 --> 00:07.620]  different ways to make money online and how to become a work-from-home\n",
            "[00:07.620 --> 00:12.280]  freelancer. So some of my most popular videos talk to you about transcription,\n",
            "[00:12.280 --> 00:17.220]  how to transcribe audio to text and in today's tutorial I'm excited to show you\n",
            "[00:17.220 --> 00:23.820]  how you can convert audio files or video files to text completely for free\n",
            "[00:23.820 --> 00:28.680]  without any limit. We are going to be using something called whisper and\n",
            "[00:28.680 --> 00:33.440]  whisper is a machine learning model for speech recognition and transcription and\n",
            "[00:33.440 --> 00:39.240]  it's created by OpenAI. OpenAI are also the creators of ChatGPT. This is\n",
            "[00:39.240 --> 00:45.120]  completely free and whisper supports 99 languages so you can convert audio or\n",
            "[00:45.120 --> 00:50.300]  video files to text in 99 different languages using this method. Now there is\n",
            "[00:50.300 --> 00:54.320]  a way that you can install this on your computer but I know a lot of you don't\n",
            "[00:54.320 --> 00:59.080]  have really fast powerful computers so in this method we will not be installing\n",
            "[00:59.080 --> 01:04.280]  it on our computer instead we're going to use Google Collaboratory within our\n",
            "[01:04.280 --> 01:08.080]  Google Drive account and this method allows you to write and run code\n",
            "[01:08.080 --> 01:12.440]  directly in your browser so that way you could do this if you're on your computer\n",
            "[01:12.440 --> 01:16.460]  your friend's computer at work because you're not installing something on the\n",
            "[01:16.460 --> 01:22.840]  computer itself. Okay so first of all let's open Google Drive. All you need is\n",
            "[01:22.840 --> 01:27.680]  your Gmail account to access Google Drive and it's also free. Then you're\n",
            "[01:27.680 --> 01:34.800]  going to click here on new and go down and click more then click connect more\n",
            "[01:34.800 --> 01:40.480]  apps. So now we have to search for the app that we want to install so click on\n",
            "[01:40.480 --> 01:47.000]  search apps and type in Collaboratory and you're going to click on the first\n",
            "[01:47.000 --> 01:53.800]  one that pops up and now just click install then click continue they may ask\n",
            "[01:53.800 --> 01:58.040]  you to sign in with your Google account so just click on your Google account and\n",
            "[01:58.040 --> 02:05.000]  it will be installed instantly. So now just click done and close off the\n",
            "[02:05.000 --> 02:10.440]  marketplace window and now we have to open Google Collaboratory so to open it\n",
            "[02:10.440 --> 02:16.840]  just click on new once again click on more and it will show up right here\n",
            "[02:16.840 --> 02:21.520]  Google Collaboratory so just click that. So I'm going to do a demo of how we can\n",
            "[02:21.520 --> 02:26.680]  transcribe an audio file and a video file. So first we're going to transcribe\n",
            "[02:26.680 --> 02:33.120]  an audio file double click where it says untitled to rename the file but keep the\n",
            "[02:33.120 --> 02:39.640]  extension as it is and then press enter. So now click on runtime and click change\n",
            "[02:39.680 --> 02:47.560]  runtime type. So we want to change the hardware accelerator from CPU to t4 GPU\n",
            "[02:47.560 --> 02:54.800]  then click Save. So now we need to install whisper AI and FFmpeg to be\n",
            "[02:54.800 --> 02:59.760]  able to work with both audio and video files and remember we are not installing\n",
            "[02:59.760 --> 03:05.000]  this on our computer but instead in Google collab and this might seem\n",
            "[03:05.000 --> 03:09.000]  complicated but just follow the instructions and you'll see how easy it\n",
            "[03:09.040 --> 03:15.640]  is. So in the description below I have pasted this code so go into the\n",
            "[03:15.640 --> 03:20.760]  description below and copy and paste this exact code and you're going to\n",
            "[03:20.760 --> 03:27.320]  paste it in this field right here then click run cell on this icon to run the\n",
            "[03:27.320 --> 03:32.480]  code and this will go ahead and install whisper and FFmpeg and it should only\n",
            "[03:32.480 --> 03:38.560]  take a few minutes. You can see here it took three minutes to install so now\n",
            "[03:38.600 --> 03:44.280]  we're ready to upload our file. On the left click here on this folder icon and\n",
            "[03:44.280 --> 03:50.560]  what you're going to do is drag and drop your audio or video file into this\n",
            "[03:50.560 --> 03:56.000]  section here on the left. So this warning will pop up basically telling you to\n",
            "[03:56.000 --> 04:00.920]  save your files on your computer because the runtimes files will be deleted when\n",
            "[04:01.000 --> 04:05.240]  this runtime is terminated. So once it's finished transcribing and you're\n",
            "[04:05.240 --> 04:10.680]  finished your session on Google collab it will erase this audio or video file.\n",
            "[04:11.480 --> 04:18.040]  So now we want to get the text from this file. So click here on code and\n",
            "[04:18.040 --> 04:23.920]  we're going to insert this code here. Again I have pasted this code in the\n",
            "[04:23.920 --> 04:29.800]  description below so paste that in here and then replace your file name with\n",
            "[04:29.800 --> 04:36.560]  your exact file name including the spaces and the extension. So in my case\n",
            "[04:36.560 --> 04:45.640]  it was corporate-day-sample.mp3. Then click run cell. So that will begin\n",
            "[04:45.640 --> 04:51.000]  extracting the text from the file. You can see it's automatically detecting\n",
            "[04:51.000 --> 04:56.320]  that this file is in English and right here it is transcribing it perfectly\n",
            "[04:56.320 --> 05:02.080]  with punctuation, capitalization and even with timestamps. So in our first\n",
            "[05:02.080 --> 05:06.760]  demo this is around a two-minute file so we're going to see how long it takes to\n",
            "[05:06.760 --> 05:12.080]  transcribe a two-minute file. You can see it took 50 seconds so in order to\n",
            "[05:12.080 --> 05:16.800]  download this transcript just wait a few seconds and you will have a few\n",
            "[05:16.800 --> 05:21.720]  different options on the side here. So you can see here there's a .srt file\n",
            "[05:21.720 --> 05:25.960]  which is your typical subtitle file that you can upload to YouTube for example\n",
            "[05:26.000 --> 05:31.720]  and a .txt file. If these haven't popped up for you just click on the refresh\n",
            "[05:31.720 --> 05:38.520]  icon here. So to download any of these files let's try the .txt one just hover\n",
            "[05:38.520 --> 05:44.640]  over it and then click on the icon here and click download and let's do the\n",
            "[05:44.640 --> 05:49.480]  same for the subtitle file and I'll show you what they look like. So this is the\n",
            "[05:49.480 --> 05:54.640]  .txt file and you can see it's done an amazing job this is perfect. There's\n",
            "[05:54.720 --> 05:59.880]  punctuation, it's broken up the sentences correctly, it's even used hyphens\n",
            "[05:59.880 --> 06:05.600]  correctly and if we open up the .srt file you can see it has done captions\n",
            "[06:05.600 --> 06:10.320]  for us so we could go ahead and upload this to YouTube. So now I want to quickly\n",
            "[06:10.320 --> 06:14.880]  show you what it's like when you upload a video file and this video file is\n",
            "[06:14.880 --> 06:20.320]  around 12 minutes long. So once again you're going to drag and drop your file\n",
            "[06:20.320 --> 06:26.320]  over here on the left and the file will start to upload and once the file has\n",
            "[06:26.320 --> 06:30.040]  finished uploading you'll see it in the list here so you can see types of\n",
            "[06:30.040 --> 06:36.240]  sentences and once again you're going to click on code and we're going to paste\n",
            "[06:36.240 --> 06:41.380]  what we did before. Again you can find this code in the description below. So we\n",
            "[06:41.380 --> 06:45.800]  have to replace your file name with your file name. Now in this case it's a really\n",
            "[06:45.800 --> 06:49.480]  long file name and I don't feel like typing it out so I can actually rename\n",
            "[06:49.800 --> 06:54.960]  it by hovering my mouse over the file and clicking on the three dots icon and\n",
            "[06:54.960 --> 07:00.280]  then click rename file. I'm going to rename this to sentences so it's easier.\n",
            "[07:00.280 --> 07:05.840]  So now replace your file name with sentences and remember to put the\n",
            "[07:05.840 --> 07:11.560]  extension it won't work if you don't put the extension so sentences.mp4 in this\n",
            "[07:11.560 --> 07:17.920]  case and then click run cell. So once again it's going to begin transcribing\n",
            "[07:17.920 --> 07:26.120]  and it only took two minutes to transcribe this 12-minute file and if\n",
            "[07:26.120 --> 07:29.560]  you know anything about transcription you know it takes a long time to\n",
            "[07:29.560 --> 07:34.240]  manually type this out especially considering its added punctuation and\n",
            "[07:34.240 --> 07:38.320]  capitalization and everything else. So again if you wait a few seconds you can\n",
            "[07:38.360 --> 07:44.120]  see here we can download the .txt file or the .srt file and it's done an\n",
            "[07:44.120 --> 07:50.240]  amazing job so quickly. So you can go ahead and transcribe as many files as\n",
            "[07:50.240 --> 07:55.000]  you like using this method. Now once you're done your session and you close\n",
            "[07:55.000 --> 07:59.720]  Google Drive when you open it again to transcribe you'll have to repeat this\n",
            "[07:59.720 --> 08:04.480]  process once again. So it does take around three minutes or so to install\n",
            "[08:04.480 --> 08:09.480]  Whisper but it's definitely worth it considering how fast it transcribes and\n",
            "[08:09.480 --> 08:13.680]  if you were to do this manually it could take you hours. So I hope you guys\n",
            "[08:13.680 --> 08:17.680]  enjoyed this tutorial make sure to subscribe to my channel for more videos\n",
            "[08:17.680 --> 08:21.320]  like this one if you have any questions feel free to ask me in the comment\n",
            "[08:21.320 --> 08:25.280]  section I really hope you enjoyed this let me know if it works for you and I'll\n",
            "[08:25.280 --> 08:28.760]  see you guys in my next tutorial.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrsxPgYlCn4O",
        "outputId": "4b48eb8f-1469-4bff-faa2-22e9d04d3d8d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper [-h] [--model MODEL] [--model_dir MODEL_DIR] [--device DEVICE]\n",
            "               [--output_dir OUTPUT_DIR] [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "               [--verbose VERBOSE] [--task {transcribe,translate}]\n",
            "               [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "               [--temperature TEMPERATURE] [--best_of BEST_OF] [--beam_size BEAM_SIZE]\n",
            "               [--patience PATIENCE] [--length_penalty LENGTH_PENALTY]\n",
            "               [--suppress_tokens SUPPRESS_TOKENS] [--initial_prompt INITIAL_PROMPT]\n",
            "               [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT] [--fp16 FP16]\n",
            "               [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "               [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "               [--logprob_threshold LOGPROB_THRESHOLD] [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "               [--word_timestamps WORD_TIMESTAMPS] [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "               [--append_punctuations APPEND_PUNCTUATIONS] [--highlight_words HIGHLIGHT_WORDS]\n",
            "               [--max_line_width MAX_LINE_WIDTH] [--max_line_count MAX_LINE_COUNT]\n",
            "               [--max_words_per_line MAX_WORDS_PER_LINE] [--threads THREADS]\n",
            "               [--clip_timestamps CLIP_TIMESTAMPS]\n",
            "               [--hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD]\n",
            "               audio [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio                 audio file(s) to transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  --model MODEL         name of the Whisper model to use (default: small)\n",
            "  --model_dir MODEL_DIR\n",
            "                        the path to save model files; uses ~/.cache/whisper by default (default:\n",
            "                        None)\n",
            "  --device DEVICE       device to use for PyTorch inference (default: cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "                        directory to save the outputs (default: .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "                        format of the output file; if not specified, all available formats will be\n",
            "                        produced (default: all)\n",
            "  --verbose VERBOSE     whether to print out the progress and debug messages (default: True)\n",
            "  --task {transcribe,translate}\n",
            "                        whether to perform X->X speech recognition ('transcribe') or X->English\n",
            "                        translation ('translate') (default: transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,yue,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Cantonese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Mandarin,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "                        language spoken in the audio, specify None to perform language detection\n",
            "                        (default: None)\n",
            "  --temperature TEMPERATURE\n",
            "                        temperature to use for sampling (default: 0)\n",
            "  --best_of BEST_OF     number of candidates when sampling with non-zero temperature (default: 5)\n",
            "  --beam_size BEAM_SIZE\n",
            "                        number of beams in beam search, only applicable when temperature is zero\n",
            "                        (default: 5)\n",
            "  --patience PATIENCE   optional patience value to use in beam decoding, as in\n",
            "                        https://arxiv.org/abs/2204.05424, the default (1.0) is equivalent to\n",
            "                        conventional beam search (default: None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "                        optional token length penalty coefficient (alpha) as in\n",
            "                        https://arxiv.org/abs/1609.08144, uses simple length normalization by\n",
            "                        default (default: None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "                        comma-separated list of token ids to suppress during sampling; '-1' will\n",
            "                        suppress most special characters except common punctuations (default: -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "                        optional text to provide as a prompt for the first window. (default: None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "                        if True, provide the previous output of the model as a prompt for the next\n",
            "                        window; disabling may make the text inconsistent across windows, but the\n",
            "                        model becomes less prone to getting stuck in a failure loop (default:\n",
            "                        True)\n",
            "  --fp16 FP16           whether to perform inference in fp16; True by default (default: True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "                        temperature to increase when falling back when the decoding fails to meet\n",
            "                        either of the thresholds below (default: 0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "                        if the gzip compression ratio is higher than this value, treat the\n",
            "                        decoding as failed (default: 2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "                        if the average log probability is lower than this value, treat the\n",
            "                        decoding as failed (default: -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "                        if the probability of the <|nospeech|> token is higher than this value AND\n",
            "                        the decoding has failed due to `logprob_threshold`, consider the segment\n",
            "                        as silence (default: 0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "                        (experimental) extract word-level timestamps and refine the results based\n",
            "                        on them (default: False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the next\n",
            "                        word (default: \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "                        if word_timestamps is True, merge these punctuation symbols with the\n",
            "                        previous word (default: \"'.。,，!！?？:：”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "                        (requires --word_timestamps True) underline each word as it is spoken in\n",
            "                        srt and vtt (default: False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "                        (requires --word_timestamps True) the maximum number of characters in a\n",
            "                        line before breaking the line (default: None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "                        (requires --word_timestamps True) the maximum number of lines in a segment\n",
            "                        (default: None)\n",
            "  --max_words_per_line MAX_WORDS_PER_LINE\n",
            "                        (requires --word_timestamps True, no effect with --max_line_width) the\n",
            "                        maximum number of words in a segment (default: None)\n",
            "  --threads THREADS     number of threads used by torch for CPU inference; supercedes\n",
            "                        MKL_NUM_THREADS/OMP_NUM_THREADS (default: 0)\n",
            "  --clip_timestamps CLIP_TIMESTAMPS\n",
            "                        comma-separated list start,end,start,end,... timestamps (in seconds) of\n",
            "                        clips to process, where the last end timestamp defaults to the end of the\n",
            "                        file (default: 0)\n",
            "  --hallucination_silence_threshold HALLUCINATION_SILENCE_THRESHOLD\n",
            "                        (requires --word_timestamps True) skip silent periods longer than this\n",
            "                        threshold (in seconds) when a possible hallucination is detected (default:\n",
            "                        None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gtts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAy5Dc-MFrXI",
        "outputId": "8b1d40a1-aa46-4517-c83a-c02247adc5b7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "result_text = re.sub(r'\\[\\d+:\\d+\\.\\d+ --> \\d+:\\d+\\.\\d+\\]\\s+', '', result_text)\n",
        "result_text = result_text.replace('\\n', ' ')\n",
        "result_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "j1Hkrkd2H570",
        "outputId": "a22100da-f54b-4a55-88c0-f2b9ddddd7bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello everyone and welcome back to my channel Jennifer Marie where I teach you different ways to make money online and how to become a work-from-home freelancer. So some of my most popular videos talk to you about transcription, how to transcribe audio to text and in today's tutorial I'm excited to show you how you can convert audio files or video files to text completely for free without any limit. We are going to be using something called whisper and whisper is a machine learning model for speech recognition and transcription and it's created by OpenAI. OpenAI are also the creators of ChatGPT. This is completely free and whisper supports 99 languages so you can convert audio or video files to text in 99 different languages using this method. Now there is a way that you can install this on your computer but I know a lot of you don't have really fast powerful computers so in this method we will not be installing it on our computer instead we're going to use Google Collaboratory within our Google Drive account and this method allows you to write and run code directly in your browser so that way you could do this if you're on your computer your friend's computer at work because you're not installing something on the computer itself. Okay so first of all let's open Google Drive. All you need is your Gmail account to access Google Drive and it's also free. Then you're going to click here on new and go down and click more then click connect more apps. So now we have to search for the app that we want to install so click on search apps and type in Collaboratory and you're going to click on the first one that pops up and now just click install then click continue they may ask you to sign in with your Google account so just click on your Google account and it will be installed instantly. So now just click done and close off the marketplace window and now we have to open Google Collaboratory so to open it just click on new once again click on more and it will show up right here Google Collaboratory so just click that. So I'm going to do a demo of how we can transcribe an audio file and a video file. So first we're going to transcribe an audio file double click where it says untitled to rename the file but keep the extension as it is and then press enter. So now click on runtime and click change runtime type. So we want to change the hardware accelerator from CPU to t4 GPU then click Save. So now we need to install whisper AI and FFmpeg to be able to work with both audio and video files and remember we are not installing this on our computer but instead in Google collab and this might seem complicated but just follow the instructions and you'll see how easy it is. So in the description below I have pasted this code so go into the description below and copy and paste this exact code and you're going to paste it in this field right here then click run cell on this icon to run the code and this will go ahead and install whisper and FFmpeg and it should only take a few minutes. You can see here it took three minutes to install so now we're ready to upload our file. On the left click here on this folder icon and what you're going to do is drag and drop your audio or video file into this section here on the left. So this warning will pop up basically telling you to save your files on your computer because the runtimes files will be deleted when this runtime is terminated. So once it's finished transcribing and you're finished your session on Google collab it will erase this audio or video file. So now we want to get the text from this file. So click here on code and we're going to insert this code here. Again I have pasted this code in the description below so paste that in here and then replace your file name with your exact file name including the spaces and the extension. So in my case it was corporate-day-sample.mp3. Then click run cell. So that will begin extracting the text from the file. You can see it's automatically detecting that this file is in English and right here it is transcribing it perfectly with punctuation, capitalization and even with timestamps. So in our first demo this is around a two-minute file so we're going to see how long it takes to transcribe a two-minute file. You can see it took 50 seconds so in order to download this transcript just wait a few seconds and you will have a few different options on the side here. So you can see here there's a .srt file which is your typical subtitle file that you can upload to YouTube for example and a .txt file. If these haven't popped up for you just click on the refresh icon here. So to download any of these files let's try the .txt one just hover over it and then click on the icon here and click download and let's do the same for the subtitle file and I'll show you what they look like. So this is the .txt file and you can see it's done an amazing job this is perfect. There's punctuation, it's broken up the sentences correctly, it's even used hyphens correctly and if we open up the .srt file you can see it has done captions for us so we could go ahead and upload this to YouTube. So now I want to quickly show you what it's like when you upload a video file and this video file is around 12 minutes long. So once again you're going to drag and drop your file over here on the left and the file will start to upload and once the file has finished uploading you'll see it in the list here so you can see types of sentences and once again you're going to click on code and we're going to paste what we did before. Again you can find this code in the description below. So we have to replace your file name with your file name. Now in this case it's a really long file name and I don't feel like typing it out so I can actually rename it by hovering my mouse over the file and clicking on the three dots icon and then click rename file. I'm going to rename this to sentences so it's easier. So now replace your file name with sentences and remember to put the extension it won't work if you don't put the extension so sentences.mp4 in this case and then click run cell. So once again it's going to begin transcribing and it only took two minutes to transcribe this 12-minute file and if you know anything about transcription you know it takes a long time to manually type this out especially considering its added punctuation and capitalization and everything else. So again if you wait a few seconds you can see here we can download the .txt file or the .srt file and it's done an amazing job so quickly. So you can go ahead and transcribe as many files as you like using this method. Now once you're done your session and you close Google Drive when you open it again to transcribe you'll have to repeat this process once again. So it does take around three minutes or so to install Whisper but it's definitely worth it considering how fast it transcribes and if you were to do this manually it could take you hours. So I hope you guys enjoyed this tutorial make sure to subscribe to my channel for more videos like this one if you have any questions feel free to ask me in the comment section I really hope you enjoyed this let me know if it works for you and I'll see you guys in my next tutorial. \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# given the Transcipts ready we would conver text to speech\n",
        "from gtts import gTTS\n",
        "language = \"en\"\n",
        "speech = gTTS(text = result_text, lang = language,slow = False )\n",
        "speech.save(\"Test.mp3\")"
      ],
      "metadata": {
        "id": "0kTWGO0GDpfP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3giLAwa_HumQ"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}